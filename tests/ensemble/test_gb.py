from unittest import TestCase
import sklearn_pmml_model
from sklearn_pmml_model.ensemble import PMMLGradientBoostingClassifier
from sklearn2pmml.pipeline import PMMLPipeline
from sklearn2pmml import sklearn2pmml
from sklearn.experimental import enable_hist_gradient_boosting
from sklearn.ensemble import GradientBoostingClassifier, HistGradientBoostingClassifier
from io import StringIO
import numpy as np
from os import path, remove
import pandas as pd


BASE_DIR = path.dirname(sklearn_pmml_model.__file__)


class TestGradientBoosting(TestCase):
  def test_invalid_model(self):
    with self.assertRaises(Exception) as cm:
      PMMLGradientBoostingClassifier(pmml=StringIO("""
      <PMML xmlns="http://www.dmg.org/PMML-4_3" version="4.3">
        <DataDictionary>
          <DataField name="Class" optype="categorical" dataType="string">
            <Value value="setosa"/>
            <Value value="versicolor"/>
            <Value value="virginica"/>
          </DataField>
        </DataDictionary>
        <MiningSchema>
          <MiningField name="Class" usageType="target"/>
        </MiningSchema>
      </PMML>
      """))

    assert str(cm.exception) == 'PMML model does not contain MiningModel.'

  def test_invalid_segmentation(self):
    with self.assertRaises(Exception) as cm:
      PMMLGradientBoostingClassifier(pmml=StringIO("""
      <PMML xmlns="http://www.dmg.org/PMML-4_3" version="4.3">
        <DataDictionary>
          <DataField name="Class" optype="categorical" dataType="string">
            <Value value="setosa"/>
            <Value value="versicolor"/>
            <Value value="virginica"/>
          </DataField>
        </DataDictionary>
        <MiningModel>
          <MiningSchema>
            <MiningField name="Class" usageType="target"/>
          </MiningSchema>
        </MiningModel>
      </PMML>
      """))

    assert str(cm.exception) == 'PMML model does not contain Segmentation.'

  def test_non_voting_ensemble(self):
    with self.assertRaises(Exception) as cm:
      PMMLGradientBoostingClassifier(pmml=StringIO("""
      <PMML xmlns="http://www.dmg.org/PMML-4_3" version="4.3">
        <DataDictionary>
          <DataField name="Class" optype="categorical" dataType="string">
            <Value value="setosa"/>
            <Value value="versicolor"/>
            <Value value="virginica"/>
          </DataField>
        </DataDictionary>
        <MiningModel>
          <MiningSchema>
            <MiningField name="Class" usageType="target"/>
          </MiningSchema>
          <Segmentation multipleModelMethod="mean" />
        </MiningModel>
      </PMML>
      """))

    assert str(cm.exception) == 'PMML model ensemble should use modelChain.'

  def test_fit_exception(self):
    with self.assertRaises(Exception) as cm:
      pmml = path.join(BASE_DIR, '../models/gb-xgboost-iris.pmml')
      clf = PMMLGradientBoostingClassifier(pmml)
      clf.fit(np.array([[]]), np.array([]))

    assert str(cm.exception) == 'Not supported.'


class TestIrisGradientBoostingIntegration(TestCase):
  def setUp(self):
    from sklearn.datasets import load_iris
    iris = load_iris()
    X = pd.DataFrame(iris.data)
    X.columns = np.array(['sepal_length', 'sepal_width', 'petal_length',
                          'petal_width'])
    y = pd.Series(np.array(np.array(['setosa', 'versicolor', 'virginica']))[iris.target])
    y.name = "Class"
    self.test = X, y
    self.ref = GradientBoostingClassifier(n_estimators=100, random_state=1).fit(X, y)

  def test_sklearn2pmml(self):
    # Export to PMML
    pipeline = PMMLPipeline([
      ("classifier", self.ref)
    ])
    pipeline.fit(self.test[0], self.test[1])

    sklearn2pmml(pipeline, "gb-sklearn2pmml.pmml", with_repr = True)

    try:
      # Import PMML
      model = PMMLGradientBoostingClassifier(pmml='gb-sklearn2pmml.pmml')

      # Verify classification
      Xte, yte = self.test

      assert np.array_equal(
        self.ref.score(Xte, yte),
        model.score(Xte, yte)
      )

      assert np.allclose(
        self.ref.predict_proba(Xte),
        model.predict_proba(Xte)
      )

    finally:
      remove("gb-sklearn2pmml.pmml")

  def test_R_r2pmml_xgboost(self):
    pmml = path.join(BASE_DIR, '../models/gb-xgboost-iris.pmml')
    clf = PMMLGradientBoostingClassifier(pmml)

    # Verify classification
    Xte, yte = self.test

    ref = 0.9933333333333333
    assert ref == clf.score(Xte, yte)

    ref = [
      [0.9760594257941966, 0.0128724629749537, 0.0110681112308498],
      [0.9757426417447441, 0.0128682851648328, 0.0113890730904230],
      [0.9760594257941966, 0.0128724629749537, 0.0110681112308498],
      [0.9760594257941966, 0.0128724629749537, 0.0110681112308498],
      [0.9760594257941966, 0.0128724629749537, 0.0110681112308498],
      [0.9760594257941966, 0.0128724629749537, 0.0110681112308498],
      [0.9760594257941966, 0.0128724629749537, 0.0110681112308498],
      [0.9760594257941966, 0.0128724629749537, 0.0110681112308498],
      [0.9757426417447441, 0.0128682851648328, 0.0113890730904230],
      [0.9760594257941966, 0.0128724629749537, 0.0110681112308498],
      [0.9760594257941966, 0.0128724629749537, 0.0110681112308498],
      [0.9760594257941966, 0.0128724629749537, 0.0110681112308498],
      [0.9757426417447441, 0.0128682851648328, 0.0113890730904230],
      [0.9757426417447441, 0.0128682851648328, 0.0113890730904230],
      [0.9760594257941966, 0.0128724629749537, 0.0110681112308498],
      [0.9760594257941966, 0.0128724629749537, 0.0110681112308498],
      [0.9760594257941966, 0.0128724629749537, 0.0110681112308498],
      [0.9760594257941966, 0.0128724629749537, 0.0110681112308498],
      [0.9760594257941966, 0.0128724629749537, 0.0110681112308498],
      [0.9760594257941966, 0.0128724629749537, 0.0110681112308498],
      [0.9760594257941966, 0.0128724629749537, 0.0110681112308498],
      [0.9760594257941966, 0.0128724629749537, 0.0110681112308498],
      [0.9760594257941966, 0.0128724629749537, 0.0110681112308498],
      [0.9760594257941966, 0.0128724629749537, 0.0110681112308498],
      [0.9760594257941966, 0.0128724629749537, 0.0110681112308498],
      [0.9757426417447441, 0.0128682851648328, 0.0113890730904230],
      [0.9760594257941966, 0.0128724629749537, 0.0110681112308498],
      [0.9760594257941966, 0.0128724629749537, 0.0110681112308498],
      [0.9760594257941966, 0.0128724629749537, 0.0110681112308498],
      [0.9760594257941966, 0.0128724629749537, 0.0110681112308498],
      [0.9760594257941966, 0.0128724629749537, 0.0110681112308498],
      [0.9760594257941966, 0.0128724629749537, 0.0110681112308498],
      [0.9760594257941966, 0.0128724629749537, 0.0110681112308498],
      [0.9760594257941966, 0.0128724629749537, 0.0110681112308498],
      [0.9760594257941966, 0.0128724629749537, 0.0110681112308498],
      [0.9760594257941966, 0.0128724629749537, 0.0110681112308498],
      [0.9760594257941966, 0.0128724629749537, 0.0110681112308498],
      [0.9760594257941966, 0.0128724629749537, 0.0110681112308498],
      [0.9757426417447441, 0.0128682851648328, 0.0113890730904230],
      [0.9760594257941966, 0.0128724629749537, 0.0110681112308498],
      [0.9760594257941966, 0.0128724629749537, 0.0110681112308498],
      [0.9757426417447441, 0.0128682851648328, 0.0113890730904230],
      [0.9760594257941966, 0.0128724629749537, 0.0110681112308498],
      [0.9760594257941966, 0.0128724629749537, 0.0110681112308498],
      [0.9760594257941966, 0.0128724629749537, 0.0110681112308498],
      [0.9757426417447441, 0.0128682851648328, 0.0113890730904230],
      [0.9760594257941966, 0.0128724629749537, 0.0110681112308498],
      [0.9760594257941966, 0.0128724629749537, 0.0110681112308498],
      [0.9760594257941966, 0.0128724629749537, 0.0110681112308498],
      [0.9760594257941966, 0.0128724629749537, 0.0110681112308498],
      [0.0106166153088319, 0.9785400205188246, 0.0108433641723436],
      [0.0106166153088319, 0.9785400205188246, 0.0108433641723436],
      [0.0101155963333861, 0.9323607906747136, 0.0575236129919005],
      [0.0119572590868193, 0.9754718678170027, 0.0125708730961781],
      [0.0106132395880432, 0.9782288782391356, 0.0111578821728212],
      [0.0106132395880432, 0.9782288782391356, 0.0111578821728212],
      [0.0159323759619904, 0.9288613767350993, 0.0552062473029103],
      [0.0124389433616677, 0.9744837805406320, 0.0130772760977003],
      [0.0106132395880432, 0.9782288782391356, 0.0111578821728212],
      [0.0106132395880432, 0.9782288782391356, 0.0111578821728212],
      [0.0140073718554280, 0.9712664360693611, 0.0147261920752109],
      [0.0106132395880432, 0.9782288782391356, 0.0111578821728212],
      [0.0141667403550577, 0.9709395207122262, 0.0148937389327162],
      [0.0106132395880432, 0.9782288782391356, 0.0111578821728212],
      [0.0106132395880432, 0.9782288782391356, 0.0111578821728212],
      [0.0106166153088319, 0.9785400205188246, 0.0108433641723436],
      [0.0106132395880432, 0.9782288782391356, 0.0111578821728212],
      [0.0106132395880432, 0.9782288782391356, 0.0111578821728212],
      [0.0141667403550577, 0.9709395207122262, 0.0148937389327162],
      [0.0106132395880432, 0.9782288782391356, 0.0111578821728212],
      [0.0345623929310359, 0.4340977426739484, 0.5313398643950156],
      [0.0106132395880432, 0.9782288782391356, 0.0111578821728212],
      [0.0100985567108226, 0.9307902380901225, 0.0591112051990549],
      [0.0106132395880432, 0.9782288782391356, 0.0111578821728212],
      [0.0106132395880432, 0.9782288782391356, 0.0111578821728212],
      [0.0106132395880432, 0.9782288782391356, 0.0111578821728212],
      [0.0104458453096068, 0.9628000437291715, 0.0267541109612217],
      [0.0367540158081575, 0.7002838055528258, 0.2629621786390166],
      [0.0106132395880432, 0.9782288782391356, 0.0111578821728212],
      [0.0106132395880432, 0.9782288782391356, 0.0111578821728212],
      [0.0106132395880432, 0.9782288782391356, 0.0111578821728212],
      [0.0106132395880432, 0.9782288782391356, 0.0111578821728212],
      [0.0106132395880432, 0.9782288782391356, 0.0111578821728212],
      [0.0498135826560765, 0.4929875804501168, 0.4571988368938067],
      [0.0106132395880432, 0.9782288782391356, 0.0111578821728212],
      [0.0159323759619904, 0.9288613767350993, 0.0552062473029103],
      [0.0106166153088319, 0.9785400205188246, 0.0108433641723436],
      [0.0119572590868193, 0.9754718678170027, 0.0125708730961781],
      [0.0106132395880432, 0.9782288782391356, 0.0111578821728212],
      [0.0106132395880432, 0.9782288782391356, 0.0111578821728212],
      [0.0106132395880432, 0.9782288782391356, 0.0111578821728212],
      [0.0106132395880432, 0.9782288782391356, 0.0111578821728212],
      [0.0106132395880432, 0.9782288782391356, 0.0111578821728212],
      [0.0140073718554280, 0.9712664360693611, 0.0147261920752109],
      [0.0106132395880432, 0.9782288782391356, 0.0111578821728212],
      [0.0106132395880432, 0.9782288782391356, 0.0111578821728212],
      [0.0106132395880432, 0.9782288782391356, 0.0111578821728212],
      [0.0106132395880432, 0.9782288782391356, 0.0111578821728212],
      [0.0106132395880432, 0.9782288782391356, 0.0111578821728212],
      [0.0106132395880432, 0.9782288782391356, 0.0111578821728212],
      [0.0108567094134873, 0.0144905851493065, 0.9746527054372062],
      [0.0164145902620253, 0.0255525167427301, 0.9580328929952446],
      [0.0108613904938508, 0.0140656636934379, 0.9750729458127113],
      [0.0108777095343255, 0.0125843153938132, 0.9765379750718612],
      [0.0108777095343255, 0.0125843153938132, 0.9765379750718612],
      [0.0108613904938508, 0.0140656636934379, 0.9750729458127113],
      [0.0435806598526578, 0.2599986718108350, 0.6964206683365073],
      [0.0108613904938508, 0.0140656636934379, 0.9750729458127113],
      [0.0108613904938508, 0.0140656636934379, 0.9750729458127113],
      [0.0108567094134873, 0.0144905851493065, 0.9746527054372062],
      [0.0142345906453859, 0.0312354373543125, 0.9545299720003015],
      [0.0108777095343255, 0.0125843153938132, 0.9765379750718612],
      [0.0108613904938508, 0.0140656636934379, 0.9750729458127113],
      [0.0184930026637306, 0.0305865778733861, 0.9509204194628834],
      [0.0164145902620253, 0.0255525167427301, 0.9580328929952446],
      [0.0108567094134873, 0.0144905851493065, 0.9746527054372062],
      [0.0108777095343255, 0.0125843153938132, 0.9765379750718612],
      [0.0108567094134873, 0.0144905851493065, 0.9746527054372062],
      [0.0108613904938508, 0.0140656636934379, 0.9750729458127113],
      [0.0510645228555055, 0.2463746443944004, 0.7025608327500941],
      [0.0108567094134873, 0.0144905851493065, 0.9746527054372062],
      [0.0184930026637306, 0.0305865778733861, 0.9509204194628834],
      [0.0108613904938508, 0.0140656636934379, 0.9750729458127113],
      [0.0125007199528260, 0.0186054175395307, 0.9688938625076433],
      [0.0108567094134873, 0.0144905851493065, 0.9746527054372062],
      [0.0108567094134873, 0.0144905851493065, 0.9746527054372062],
      [0.0299366378213490, 0.0965402806010371, 0.8735230815776139],
      [0.0120440726761590, 0.0544554457865047, 0.9335004815373361],
      [0.0108777095343255, 0.0125843153938132, 0.9765379750718612],
      [0.0464351273705071, 0.2443049639688132, 0.7092599086606799],
      [0.0108613904938508, 0.0140656636934379, 0.9750729458127113],
      [0.0108567094134873, 0.0144905851493065, 0.9746527054372062],
      [0.0108777095343255, 0.0125843153938132, 0.9765379750718612],
      [0.0363615404352432, 0.1786334851333196, 0.7850049744314372],
      [0.0252911348271332, 0.0660520596210707, 0.9086568055517961],
      [0.0108613904938508, 0.0140656636934379, 0.9750729458127113],
      [0.0108567094134873, 0.0144905851493065, 0.9746527054372062],
      [0.0108777095343255, 0.0125843153938132, 0.9765379750718612],
      [0.0250153077815250, 0.2450614165877344, 0.7299232756307406],
      [0.0108613904938508, 0.0140656636934379, 0.9750729458127113],
      [0.0108613904938508, 0.0140656636934379, 0.9750729458127113],
      [0.0142478270786007, 0.0303346044639386, 0.9554175684574607],
      [0.0164145902620253, 0.0255525167427301, 0.9580328929952446],
      [0.0108567094134873, 0.0144905851493065, 0.9746527054372062],
      [0.0108567094134873, 0.0144905851493065, 0.9746527054372062],
      [0.0108613904938508, 0.0140656636934379, 0.9750729458127113],
      [0.0125007199528260, 0.0186054175395307, 0.9688938625076433],
      [0.0108777095343255, 0.0125843153938132, 0.9765379750718612],
      [0.0108567094134873, 0.0144905851493065, 0.9746527054372062],
      [0.0162658935674777, 0.0343798537311987, 0.9493542527013236],
    ]
    assert np.allclose(
      ref,
      clf.predict_proba(Xte)
    )

  def test_R_pmml_gbm(self):
    pmml = path.join(BASE_DIR, '../models/gb-gbm-iris.pmml')
    clf = PMMLGradientBoostingClassifier(pmml)

    # Verify classification
    Xte, yte = self.test

    ref = 0.9933333333333333
    assert ref == clf.score(Xte, yte)

    ref = [
      [0.9999514353886586, 0.0000484979008534, 0.0000000667104879],
      [0.9999875671449452, 0.0000121882917269, 0.0000002445633279],
      [0.9999727167846543, 0.0000271985201417, 0.0000000846952040],
      [0.9999809119352389, 0.0000189428040082, 0.0000001452607529],
      [0.9999514353886586, 0.0000484979008534, 0.0000000667104879],
      [0.9999437378266295, 0.0000561954633961, 0.0000000667099744],
      [0.9999727167846543, 0.0000271985201417, 0.0000000846952040],
      [0.9999514353886586, 0.0000484979008534, 0.0000000667104879],
      [0.9999875671449452, 0.0000121882917269, 0.0000002445633279],
      [0.9999809119352389, 0.0000189428040082, 0.0000001452607529],
      [0.9999437378266295, 0.0000561954633961, 0.0000000667099744],
      [0.9999727167846543, 0.0000271985201417, 0.0000000846952040],
      [0.9999875671449452, 0.0000121882917269, 0.0000002445633279],
      [0.9999875671449452, 0.0000121882917269, 0.0000002445633279],
      [0.9999437378266295, 0.0000561954633961, 0.0000000667099744],
      [0.9999437378266295, 0.0000561954633961, 0.0000000667099744],
      [0.9999437378266295, 0.0000561954633961, 0.0000000667099744],
      [0.9999514353886586, 0.0000484979008534, 0.0000000667104879],
      [0.9999437378266295, 0.0000561954633961, 0.0000000667099744],
      [0.9999514353886586, 0.0000484979008534, 0.0000000667104879],
      [0.9999437378266295, 0.0000561954633961, 0.0000000667099744],
      [0.9999514353886586, 0.0000484979008534, 0.0000000667104879],
      [0.9999727167846543, 0.0000271985201417, 0.0000000846952040],
      [0.9999514353886586, 0.0000484979008534, 0.0000000667104879],
      [0.9999727167846543, 0.0000271985201417, 0.0000000846952040],
      [0.9999780740689346, 0.0000217332975927, 0.0000001926334727],
      [0.9999514353886586, 0.0000484979008534, 0.0000000667104879],
      [0.9999514353886586, 0.0000484979008534, 0.0000000667104879],
      [0.9999514353886586, 0.0000484979008534, 0.0000000667104879],
      [0.9999727167846543, 0.0000271985201417, 0.0000000846952040],
      [0.9999809119352389, 0.0000189428040082, 0.0000001452607529],
      [0.9999437378266295, 0.0000561954633961, 0.0000000667099744],
      [0.9999514353886586, 0.0000484979008534, 0.0000000667104879],
      [0.9999437378266295, 0.0000561954633961, 0.0000000667099744],
      [0.9999809119352389, 0.0000189428040082, 0.0000001452607529],
      [0.9999514353886586, 0.0000484979008534, 0.0000000667104879],
      [0.9999437378266295, 0.0000561954633961, 0.0000000667099744],
      [0.9999727167846543, 0.0000271985201417, 0.0000000846952040],
      [0.9999875671449452, 0.0000121882917269, 0.0000002445633279],
      [0.9999514353886586, 0.0000484979008534, 0.0000000667104879],
      [0.9999514353886586, 0.0000484979008534, 0.0000000667104879],
      [0.9999921124669205, 0.0000064291518097, 0.0000014583812697],
      [0.9999727167846543, 0.0000271985201417, 0.0000000846952040],
      [0.9999514353886586, 0.0000484979008534, 0.0000000667104879],
      [0.9999514353886586, 0.0000484979008534, 0.0000000667104879],
      [0.9999875671449452, 0.0000121882917269, 0.0000002445633279],
      [0.9999514353886586, 0.0000484979008534, 0.0000000667104879],
      [0.9999727167846543, 0.0000271985201417, 0.0000000846952040],
      [0.9999514353886586, 0.0000484979008534, 0.0000000667104879],
      [0.9999514353886586, 0.0000484979008534, 0.0000000667104879],
      [0.0000003855737110, 0.9999853465620077, 0.0000142678642813],
      [0.0000020399536438, 0.9996683671398233, 0.0003295929065328],
      [0.0000014221200562, 0.9988416039766718, 0.0011569739032720],
      [0.0000099837118808, 0.9808465672518768, 0.0191434490362424],
      [0.0000066770580942, 0.9932584665222453, 0.0067348564196605],
      [0.0000078824207889, 0.9945122564169859, 0.0054798611622252],
      [0.0000017317413428, 0.9996250944932090, 0.0003731737654482],
      [0.0000200063008875, 0.9512775893798490, 0.0487024043192635],
      [0.0000022900882057, 0.9993505154881452, 0.0006471944236490],
      [0.0000042418821173, 0.9983057420196200, 0.0016900160982627],
      [0.0000115333470712, 0.9778736415746325, 0.0221148250782963],
      [0.0000063243917342, 0.9975766957818183, 0.0024169798264475],
      [0.0000072240512460, 0.9834113267468383, 0.0165814492019156],
      [0.0000045140648420, 0.9979278719599650, 0.0020676139751930],
      [0.0000053597973119, 0.9982711899770359, 0.0017234502256523],
      [0.0000004694910964, 0.9999742790659164, 0.0000252514429871],
      [0.0000087436667040, 0.9953498986136428, 0.0046413577196533],
      [0.0000036616576977, 0.9985374905279942, 0.0014588478143079],
      [0.0000131956511758, 0.9404875765509882, 0.0594992277978359],
      [0.0000099837118808, 0.9808465672518768, 0.0191434490362424],
      [0.0000114271141535, 0.6557999539979311, 0.3441886188879154],
      [0.0000066336567559, 0.9934241400361198, 0.0065692263071243],
      [0.0000104934172695, 0.7733022521695532, 0.2266872544131774],
      [0.0000066336567559, 0.9934241400361198, 0.0065692263071243],
      [0.0000027810741402, 0.9992112685546718, 0.0007859503711879],
      [0.0000022900882057, 0.9993505154881452, 0.0006471944236490],
      [0.0000016255481683, 0.9988398792545891, 0.0011584951972427],
      [0.0000072792091725, 0.7910769710668615, 0.2089157497239661],
      [0.0000063142781360, 0.9959814293564363, 0.0040122563654276],
      [0.0000047676433670, 0.9959379142208491, 0.0040573181357840],
      [0.0000099837118808, 0.9808465672518768, 0.0191434490362424],
      [0.0000099837118808, 0.9808465672518768, 0.0191434490362424],
      [0.0000036616576977, 0.9985374905279942, 0.0014588478143079],
      [0.0000123694878899, 0.2516734348776127, 0.7483141956344974],
      [0.0000087436667040, 0.9953498986136428, 0.0046413577196533],
      [0.0000024101093467, 0.9992902206547756, 0.0007073692358776],
      [0.0000007681155666, 0.9999310315545515, 0.0000682003298818],
      [0.0000052299720018, 0.9911810411066942, 0.0088137289213039],
      [0.0000053597973119, 0.9982711899770359, 0.0017234502256523],
      [0.0000099837118808, 0.9808465672518768, 0.0191434490362424],
      [0.0000047676433670, 0.9959379142208491, 0.0040573181357840],
      [0.0000045140648420, 0.9979278719599650, 0.0020676139751930],
      [0.0000047676433670, 0.9959379142208491, 0.0040573181357840],
      [0.0000115333470712, 0.9778736415746325, 0.0221148250782963],
      [0.0000036616576977, 0.9985374905279942, 0.0014588478143079],
      [0.0000053597973119, 0.9982711899770359, 0.0017234502256523],
      [0.0000053597973119, 0.9982711899770359, 0.0017234502256523],
      [0.0000045140648420, 0.9979278719599650, 0.0020676139751930],
      [0.0000115333470712, 0.9778736415746325, 0.0221148250782963],
      [0.0000078824207889, 0.9945122564169859, 0.0054798611622252],
      [0.0000003703769621, 0.0008892183360207, 0.9991104112870172],
      [0.0000003574149295, 0.0009307318605632, 0.9990689107245073],
      [0.0000003391535050, 0.0011802783756313, 0.9988193824708637],
      [0.0000001648988976, 0.0002751491283698, 0.9997246859727326],
      [0.0000001283643354, 0.0001381019900108, 0.9998617696456539],
      [0.0000003391535050, 0.0011802783756313, 0.9988193824708637],
      [0.0000158984318052, 0.2213904858462341, 0.7785936157219607],
      [0.0000003391535050, 0.0011802783756313, 0.9988193824708637],
      [0.0000000671810857, 0.0001454198998583, 0.9998545129190560],
      [0.0000009730623121, 0.0075567956237277, 0.9924422313139601],
      [0.0000014402464809, 0.0110269580395753, 0.9889716017139438],
      [0.0000002867264931, 0.0012122048992109, 0.9987875083742960],
      [0.0000007796294119, 0.0060724658651278, 0.9939267545054604],
      [0.0000002715690770, 0.0009223900673932, 0.9990773383635297],
      [0.0000002049708961, 0.0002469494045126, 0.9997528456245913],
      [0.0000010203225329, 0.0065745814827604, 0.9934243981947066],
      [0.0000002963594232, 0.0007136134516424, 0.9992860901889344],
      [0.0000009730623121, 0.0075567956237277, 0.9924422313139601],
      [0.0000001282351080, 0.0005005222819180, 0.9994993494829739],
      [0.0000121612893923, 0.2739865325411796, 0.7260013061694282],
      [0.0000009730623121, 0.0075567956237277, 0.9924422313139601],
      [0.0000014977762884, 0.0153499245186472, 0.9846485777050644],
      [0.0000001569961323, 0.0003701071264049, 0.9996297358774628],
      [0.0000026748390259, 0.1142977384981020, 0.8856995866628722],
      [0.0000011448181497, 0.0104836701211560, 0.9895151850606942],
      [0.0000009730623121, 0.0075567956237277, 0.9924422313139601],
      [0.0000025841931527, 0.0385644457971406, 0.9614329700097067],
      [0.0000022168229833, 0.0398080719438479, 0.9601897112331689],
      [0.0000000762852005, 0.0000862265549317, 0.9999136971598678],
      [0.0000137229815950, 0.2692929823341176, 0.7306932946842873],
      [0.0000001569961323, 0.0003701071264049, 0.9996297358774628],
      [0.0000009730623121, 0.0075567956237277, 0.9924422313139601],
      [0.0000000762852005, 0.0000862265549317, 0.9999136971598678],
      [0.0000144429897963, 0.1606894684393393, 0.8392960885708644],
      [0.0000044930548458, 0.0405223828423548, 0.9594731241027994],
      [0.0000003391535050, 0.0011802783756313, 0.9988193824708637],
      [0.0000004754377620, 0.0017703247703994, 0.9982291997918386],
      [0.0000004983770885, 0.0018651195373953, 0.9981343820855162],
      [0.0000058710323721, 0.1509872958458385, 0.8490068331217895],
      [0.0000012998267134, 0.0157349961620439, 0.9842637040112427],
      [0.0000008593169558, 0.0085000304762039, 0.9914991102068402],
      [0.0000021620500627, 0.0372917408311482, 0.9627060971187891],
      [0.0000003574149295, 0.0009307318605632, 0.9990689107245073],
      [0.0000009730623121, 0.0075567956237277, 0.9924422313139601],
      [0.0000011448181497, 0.0104836701211560, 0.9895151850606942],
      [0.0000010966854112, 0.0120785892723843, 0.9879203140422045],
      [0.0000003086524487, 0.0020223141165683, 0.9979773772309830],
      [0.0000003553289675, 0.0010260118210255, 0.9989736328500070],
      [0.0000005274455195, 0.0017438831505158, 0.9982555894039646],
      [0.0000006147486452, 0.0015149850983158, 0.9984844001530390],
    ]
    assert np.allclose(
      ref,
      clf.predict_proba(Xte)
    )


# class TestCategoricalPimaGradientBoostingIntegration(TestCase):
#   def setUp(self):
#     df = pd.read_csv(path.join(BASE_DIR, '../models/categorical-test.csv'))
#     Xte = df.iloc[:, 1:]
#     yte = df.iloc[:, 0]
#     self.test = (Xte, yte)
#
#     pmml = path.join(BASE_DIR, '../models/gb-gbm-cat-pima.pmml')
#     self.clf = PMMLGradientBoostingClassifier(pmml)
#
#     self.ref = HistGradientBoostingClassifier(n_estimators=6, random_state=1)
#
#   def test_predict_proba(self):
#     Xte, _ = self.test
#
#     ref = np.array([
#       [0.2200000000000000, 0.7800000000000000],
#       [0.5800000000000000, 0.4200000000000000],
#       [0.2200000000000000, 0.7800000000000000],
#       [0.1800000000000000, 0.8200000000000000],
#       [0.0800000000000000, 0.9200000000000000],
#       [0.3000000000000000, 0.7000000000000000],
#       [0.2600000000000000, 0.7400000000000000],
#       [0.3600000000000000, 0.6400000000000000],
#       [0.4000000000000000, 0.6000000000000000],
#       [0.1600000000000000, 0.8400000000000000],
#       [0.2200000000000000, 0.7800000000000000],
#       [0.3000000000000000, 0.7000000000000000],
#       [0.1400000000000000, 0.8600000000000000],
#       [0.6400000000000000, 0.3600000000000000],
#       [0.1800000000000000, 0.8200000000000000],
#       [0.1800000000000000, 0.8200000000000000],
#       [0.7600000000000000, 0.2400000000000000],
#       [0.2400000000000000, 0.7600000000000000],
#       [0.3400000000000000, 0.6600000000000000],
#       [0.2800000000000000, 0.7200000000000000],
#       [0.0800000000000000, 0.9200000000000000],
#       [0.2000000000000000, 0.8000000000000000],
#       [0.6800000000000000, 0.3200000000000000],
#       [0.1200000000000000, 0.8800000000000000],
#       [0.2200000000000000, 0.7800000000000000],
#       [0.3600000000000000, 0.6400000000000000],
#       [0.2000000000000000, 0.8000000000000000],
#       [0.8600000000000000, 0.1400000000000000],
#       [0.9399999999999999, 0.0600000000000000],
#       [0.7200000000000000, 0.2800000000000000],
#       [0.5600000000000001, 0.4400000000000000],
#       [0.9800000000000000, 0.0200000000000000],
#       [0.4400000000000000, 0.5600000000000001],
#       [0.8800000000000000, 0.1200000000000000],
#       [0.6600000000000000, 0.3400000000000000],
#       [0.5000000000000000, 0.5000000000000000],
#       [0.7400000000000000, 0.2600000000000000],
#       [0.2600000000000000, 0.7400000000000000],
#       [0.1600000000000000, 0.8400000000000000],
#       [0.6800000000000000, 0.3200000000000000],
#       [0.7600000000000000, 0.2400000000000000],
#       [0.7400000000000000, 0.2600000000000000],
#       [0.5600000000000001, 0.4400000000000000],
#       [0.5400000000000000, 0.4600000000000000],
#       [0.5200000000000000, 0.4800000000000000],
#       [0.1400000000000000, 0.8600000000000000],
#       [0.7600000000000000, 0.2400000000000000],
#       [0.8200000000000000, 0.1800000000000000],
#       [0.4400000000000000, 0.5600000000000001],
#       [0.9200000000000000, 0.0800000000000000],
#       [0.5600000000000001, 0.4400000000000000],
#       [0.2800000000000000, 0.7200000000000000]
#     ])
#     assert np.allclose(ref, self.clf.predict_proba(Xte))
#
#   def test_score(self):
#     Xte, yte = self.test
#     ref = 0.7884615384615384
#     assert ref == self.clf.score(Xte, yte)
